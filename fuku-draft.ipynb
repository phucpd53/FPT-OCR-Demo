{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T07:37:46.429092Z",
     "start_time": "2019-04-02T07:37:34.744213Z"
    }
   },
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T07:37:47.136054Z",
     "start_time": "2019-04-02T07:37:46.432121Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "font_path = \"/usr/share/fonts/truetype/fonts-japanese-mincho.ttf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T07:37:47.181514Z",
     "start_time": "2019-04-02T07:37:47.138128Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_line(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Otsu's thresholding\n",
    "    _,binary = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    \n",
    "    horizontal_img = binary.copy()\n",
    "    vertical_img = binary.copy()\n",
    "    \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (50,1))\n",
    "    horizontal_img = cv2.erode(horizontal_img, kernel, iterations=1)\n",
    "    horizontal_img = cv2.dilate(horizontal_img, kernel, iterations=1)\n",
    "\n",
    "    \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,40))\n",
    "    vertical_img = cv2.erode(vertical_img, kernel, iterations=1)\n",
    "    vertical_img = cv2.dilate(vertical_img, kernel, iterations=1)\n",
    "\n",
    "    mask_img = horizontal_img + vertical_img\n",
    "    mask_indx = mask_img == 255\n",
    "    img[mask_indx] = 255\n",
    "    \n",
    "    return img \n",
    "def df_to_image(df, img):\n",
    "    overlay = np.full(img.shape, 255, dtype=np.uint8)\n",
    "    pil_image = Image.fromarray(overlay)\n",
    "    draw = ImageDraw.Draw(pil_image)\n",
    "    for index, row in df.iterrows():\n",
    "        if row['conf'] != -1:\n",
    "            # cv2.putText(overlay,row['text'],(row['left'],row['top'] + row['height']), cv2.FONT_HERSHEY_SIMPLEX, img.shape[0]/1000.0,0,1,cv2.LINE_AA)\n",
    "            draw.text((row['left'],row['top'] + row['height']), row['text'], font=ImageFont.truetype(font_path, np.max(img.shape)//100), fill=0)\n",
    "    return np.array(pil_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T07:37:47.197629Z",
     "start_time": "2019-04-02T07:37:47.184034Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_next(previous, current, is_phrase=True):\n",
    "    # in case arg is phrase type\n",
    "    if is_phrase:\n",
    "        # parameters\n",
    "        space_param = 10\n",
    "        ratio_param = 0.5\n",
    "        \n",
    "        # if the space between 2 word are too far\n",
    "        if current['left'] - previous['left'] > space_param * previous['width']:\n",
    "            return False\n",
    "        # if height of 2 words are too different\n",
    "        #if abs(current['height'] - previous['height']) / current['height'] > ratio_param:\n",
    "        #    return False\n",
    "        return True\n",
    "    # in case arg is paragraph\n",
    "    else:\n",
    "        # parameters\n",
    "        space_param = 1.5\n",
    "        ratio_param = 1.0\n",
    "        \n",
    "        l_c, t_c, h_c, w_c = current[1]\n",
    "        l_p, t_p, h_p, w_p = previous[1]\n",
    "        # if the space between 2 phrase are too far\n",
    "        if t_c - t_p > space_param * h_p:\n",
    "            return False\n",
    "        # if the position of 2 phrases are not aligned (left_aligned, middle_aligned, right_aligned)\n",
    "        if min(abs(l_c - l_p), abs(l_c + w_c / 2 - l_p - w_p / 2), abs(l_c + w_c - l_p - w_p)) > ratio_param * h_p:\n",
    "            return False\n",
    "        return True\n",
    "def process_row(rows):\n",
    "    line = \"\"\n",
    "    left, top, height, width = (9999,9999,0,0) \n",
    "    for row in rows:\n",
    "        line += row['text']\n",
    "        left = min(left, row['left']) # Left of a line of characters should be the character on the left\n",
    "        top = min(top, row['top'])    # Top of a line of characters should be the the min top of all characters (each character's top is not the same)\n",
    "        height = max(height, row['top'] + row['height'] - top)\n",
    "        width = max(width, row['left'] + row['width'] - left)\n",
    "    return (line, (left, top, height, width))\n",
    "def process_line(df):\n",
    "    '''\n",
    "    @input: a dataframe\n",
    "    divide a data frame of line into different elements(blocks) \n",
    "    if these blocks locate far from eachother\n",
    "    @output: a list of tupple (phrase, location)\n",
    "    '''\n",
    "    # result will be saved here\n",
    "    phrases = []\n",
    "    \n",
    "    # initialize for for_loop\n",
    "    previous_row = df.iloc[0]\n",
    "    rows = [df.iloc[0]]\n",
    "    \n",
    "    for indx in range(1, df['text'].count()):\n",
    "        row = df.iloc[indx]\n",
    "        if is_next(previous_row, row):\n",
    "            rows.append(row)\n",
    "        else:\n",
    "            previous_item = None\n",
    "            text, location = process_row(rows)\n",
    "            phrases.append((text, location))\n",
    "            rows = [row]\n",
    "        previous_row = row\n",
    "    if len(rows) != 0:\n",
    "        text, location = process_row(rows)\n",
    "        phrases.append((text, location))\n",
    "    return phrases\n",
    " \n",
    "def process_phrases(blocks):\n",
    "    '''\n",
    "    # Sample of blocks\n",
    "    #############################################################################################\n",
    "    [('納品書', (764, 165, 41, 198))]\n",
    "    [('御中', (661, 267, 46, 68)), ('納品No.DUA①②③①②④0⑤0⑤A', (977, 269, 41, 616))]\n",
    "    [('ご担当:', (188, 343, 42, 103)), ('様', (592, 348, 28, 16)), ('納品日', (977, 344, 42, 89)), ('⑳①⑨/⑨/①⑧', (1465, 350, 26, 128))]\n",
    "    [('件名:', (145, 426, 65, 90)), ('oo株式会社', (897, 423, 65, 155))]\n",
    "    [('下記のとおり、納品致します。', (185, 480, 64, 408)), ('〒', (901, 499, 25, 21))]\n",
    "    [('東京都新宿区新宿①.②③', (899, 529, 65, 306))]\n",
    "    [('新宿第①ビル②階', (898, 596, 28, 211))]\n",
    "    [('納期:', (169, 644, 39, 70)), ('TEL:', (972, 648, 34, 58))]\n",
    "    [('支払条件:月末締め翌月末払い', (114, 679, 64, 424)), ('FAX', (969, 702, 19, 61))]\n",
    "    [('E-Mail:', (938, 749, 21, 92))]\n",
    "    [('担当', (954, 776, 65, 66))]\n",
    "    [('合計金額\\\\0(税込)', (149, 875, 52, 611))]\n",
    "    [('No.摘要', (118, 957, 67, 408)), ('数量単価', (863, 960, 64, 258)), ('金額', (1375, 960, 64, 64))]\n",
    "    [('小計', (863, 1612, 64, 76)), (\"'\", (1208, 1619, 2, 2)), ('vo', (1564, 1619, 35, 36))]\n",
    "    [('消費税', (847, 1662, 64, 104)), ('vo', (1564, 1668, 35, 36))]\n",
    "    [('合計_', (863, 1711, 64, 109)), ('vo', (1564, 1718, 35, 36))]\n",
    "    [('備考', (149, 1898, 46, 62))]\n",
    "    #############################################################################################\n",
    "    group a list of phrases into a paragraphs if these phrases are close to each other\n",
    "    '''\n",
    " \n",
    "    # declare a list containing items, that each item is a group of pharse that is close to each other\n",
    "    paragraphs = [[item] for item in blocks[0]]\n",
    "    \n",
    "    for block in blocks[1:]:\n",
    "        # declare a temporarory paragraphs to store new paragraph into\n",
    "        tmp_paragraphs = []\n",
    "        for current_item in block:\n",
    "            for indx, paragraph in enumerate(paragraphs):\n",
    "                # if current_item is close to the last item of candidate, add it to that paragraph\n",
    "                if is_next(paragraph[-1], current_item, is_phrase=False):\n",
    "                    paragraph.append(current_item)\n",
    "                    break\n",
    "                # other-wise, declare a new paragraph as this current_item\n",
    "                if indx == len(paragraphs) - 1:\n",
    "                    tmp_paragraphs.append([current_item])\n",
    "        # update paragraphs\n",
    "        if len(tmp_paragraphs) != 0:\n",
    "            paragraphs.extend(tmp_paragraphs)\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T07:42:01.723771Z",
     "start_time": "2019-04-02T07:41:59.962434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "data/nouhin_test_ocr_ImgOutput0.jpg\n",
      "####################################\n",
      "納品書\n",
      "\n",
      "御中\n",
      "\n",
      "納品No.DUA①②③①②④0⑤0⑤A\n",
      "\n",
      "ご担当:\n",
      "\n",
      "様\n",
      "\n",
      "納品日\n",
      "\n",
      "⑳①⑨/⑨/①⑧\n",
      "\n",
      "件名:\n",
      "下記のとおり、納品致します。\n",
      "\n",
      "oo株式会社\n",
      "〒\n",
      "東京都新宿区新宿①.②③\n",
      "新宿第①ビル②階\n",
      "\n",
      "納期:\n",
      "\n",
      "TEL:\n",
      "\n",
      "支払条件:月末締め翌月末払い\n",
      "\n",
      "FAX\n",
      "\n",
      "E-Mail:\n",
      "担当\n",
      "\n",
      "合計金額\\0(税込)\n",
      "\n",
      "No.摘要\n",
      "\n",
      "数量単価\n",
      "\n",
      "金額\n",
      "\n",
      "小計\n",
      "消費税\n",
      "合計_\n",
      "\n",
      "'\n",
      "\n",
      "vo\n",
      "vo\n",
      "vo\n",
      "\n",
      "備考\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 7200x7200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_folder = \"data\"\n",
    "image_paths = []\n",
    "image_paths.extend(glob(os.path.join(input_folder, \"*.png\")))\n",
    "image_paths.extend(glob(os.path.join(input_folder, \"*.jpg\")))\n",
    "image_paths = [\"data/nouhin_test_ocr_ImgOutput0.jpg\"]\n",
    "fig=plt.figure(figsize=(100, 100))\n",
    "rows = len(image_paths)\n",
    "cols = 2\n",
    "for i, path in enumerate(image_paths[:1]):\n",
    "    img = cv2.imread(path)\n",
    "    img = remove_line(img)\n",
    "    \n",
    "    # dealing with rotated image. Choose the best image's direction based on tesseract confidence score\n",
    "    df = None\n",
    "    conf = -1 \n",
    "    _img = None\n",
    "    for i in range(1):\n",
    "        img = (np.rot90(img) if i != 0 else img)\n",
    "        _df = pytesseract.image_to_data(Image.fromarray(img), lang=\"jpn\", output_type=Output.DATAFRAME)\n",
    "        _df.columns = _df.columns.str.strip()\n",
    "        _df = _df.dropna()\n",
    "        if conf < _df['conf'].mean():\n",
    "            conf = _df['conf'].mean()\n",
    "            df = _df\n",
    "            _img = img.copy()\n",
    "    \n",
    "    df.columns.str.strip()\n",
    "    df = df.dropna()\n",
    "    df = df.drop(columns=['level', 'page_num'])\n",
    "    df_lines = []\n",
    "    for _, block in df.groupby('block_num'):\n",
    "        for _, line in block.groupby('line_num'):\n",
    "            df_lines.append(line)\n",
    "    phrases = []\n",
    "    for df_line in df_lines:\n",
    "        phrases.append(process_line(df_line))\n",
    "\n",
    "    paragraphs = process_phrases(phrases)\n",
    "    print(\"####################################\")\n",
    "    print(path)\n",
    "    print(\"####################################\")\n",
    "    for paragraph in paragraphs:\n",
    "        for phrase in paragraph:\n",
    "            print(phrase[0])\n",
    "        print()\n",
    "#     new_img = df_to_image(df, _img)\n",
    "#     \n",
    "#     cv2.imwrite(os.path.join(input_folder, os.path.basename(path).split(\".\")[0] + \"_output.\" + os.path.basename(path).split(\".\")[1]), new_img)\n",
    "    \n",
    "#     fig.add_subplot(rows, cols, i * cols + 1)\n",
    "#     plt.imshow(_img.copy())\n",
    "#     fig.add_subplot(rows, cols, i * cols + 2)\n",
    "#     plt.imshow(new_img.copy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T03:11:44.917443Z",
     "start_time": "2019-04-01T03:11:44.871964Z"
    }
   },
   "source": [
    "### Not Ready yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T06:12:19.837050Z",
     "start_time": "2019-03-26T06:12:19.832414Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_to_excel(df, ws):\n",
    "    df = df.sort_values(by=['top', 'left'])\n",
    "    count = 1\n",
    "    for _, line_df in df.groupby('line_num'):\n",
    "        line = \"\".join(line_df['text'].tolist())\n",
    "        ws.cell(column=1, row=count, value=line)\n",
    "        count += 1\n",
    "    return ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T05:56:19.550293Z",
     "start_time": "2019-03-26T05:56:19.532807Z"
    }
   },
   "outputs": [],
   "source": [
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = \"Hoge\"\n",
    "ws = write_to_excel(block_df[3], ws)\n",
    "wb.save(filename=\"hoge.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T07:01:06.383861Z",
     "start_time": "2019-04-01T07:01:06.379488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['請' '求' '書' ' ' '江' '阿' '年' '|' '昌' '〒①②-⑤⑥⑦' '楠' 'COOmoomoomni②③'\n",
      " 'bSLiiSeee' '下' '記' 'の' '通' 'り' '佳' '睦' '田' 'し' 'よ' 'げ' 'ま' 'す' '。' '代'\n",
      " '表' '森' 'R' 'OOO' '〇' '①' 'W' '絵' '・' '嘆' '御' '金' '類' '節' '⑯.000-' '円'\n",
      " 'ぉ' 'kimmis' '⑳⑦' '月' '⑨' 'Co' '②' '侵' '①0000' '⑳00' 'FRNdAitAUAE' 'て'\n",
      " 'AWun' 'た' '、' '渚' '⑳' 'o' 'ama' 'を' ',' '〉' '」' 'C' 'ら' 'RR' 'COke' 'Wm'\n",
      " '①Ne⑦' 'DL' '和' '君' '肋' '⑳⑤.000']\n"
     ]
    }
   ],
   "source": [
    "print(df['text'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T07:01:28.433581Z",
     "start_time": "2019-04-01T07:01:28.430022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b' '\n"
     ]
    }
   ],
   "source": [
    "print(\" \".encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
